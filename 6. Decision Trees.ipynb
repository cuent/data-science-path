{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Visualizing a Decision Tree\n",
    "\n",
    "Convert _.dot_ file to a different format such as png or png using _graphviz_ package [1].\n",
    "\n",
    "[1] http://www.graphviz.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree_clf, out_file=\"iris_tree.dot\",\n",
    "               feature_names=iris.feature_names[2:],\n",
    "               class_names=iris.target_names,\n",
    "               rounded=True, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "- *Gini's attribute* measures a tree impurity. A node is \"pure\" (gini=0) if all training instances it applies to belong to the same class. \n",
    "\n",
    "$\\text{G}_i = 1 - \\sum_{k=1}^n{p_{i,k}}^2$, where $p_{i,k}$ is the ratio of class k instances among the training instances in the $i^{th}$ node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Estimating class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.90740741,  0.09259259]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CART training algorithm\n",
    "\n",
    "- **CART cost function**\n",
    "\n",
    "$\\text{J}(k,t_k)=\\frac{m_{left}}{m}\\text{G}_{left} + \\frac{m_{right}}{m}\\text{G}_{right}$\n",
    "\n",
    ", where \n",
    "\n",
    "$G_{left/right}$ measures the impurity of the $left/right$ subset.\n",
    "\n",
    "$m_{left/right}$ is the number of instances in the $left/right$ subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini impurity or Entropy\n",
    "\n",
    "- **Entropy** In ML is used as an impurity measure: it is zero when it contains instances of only one class.\n",
    "\n",
    "$\\text{H}_i = -\\sum_{k=1,p_{i,k}\\neq{0}}^n p_{i,k} \\cdot log(p_{i,k})$\n",
    "\n",
    "- _Which one use?_ Most of the time does not make a big difference: they lead to similar trees. Gini impurity is slightly faster to compute. However, when they differ, Gini impurity tends to isolate the most frequent class in its own branch of the tree, whie entropy tends to produce slightly more balanced trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Hyperparameters\n",
    "\n",
    "- *max_depth*: depth of the DT, default None.\n",
    "- *min_samples_split*: minimum number of samples a node must have before it can split.\n",
    "- *min_samples_leaf*: minimum number of samples a leaf node must have.\n",
    "- *min_weight_fraction*: Equal to *min_samples_leaf* but expressed as a fraction of the total number of weighted instances.\n",
    "- *max_leaf_nodes*: maximum number of leaf nodes.\n",
    "- *max_features*: maximum number of features that are evaluated for splitting at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Regression\n",
    "\n",
    "Instead of minimizing impurity CART algorithm minimizes the MSE. \n",
    "\n",
    "$\\text{J}(k,t_k) = \\frac{m_{left}}{m}\\text{MSE}_{left} + \\frac{m_{right}}{m}\\text{MSE}_{right}$\n",
    ", where\n",
    "\n",
    "$\\text{MSE}_{node} = \\sum_{i\\in\\text{node}}{(\\hat{y}_{node}-y^{(i)})^2}$\n",
    "\n",
    "$\\hat{y} = \\frac{1}{m_{node}} \\sum_{i\\in\\text{node}}y^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instability\n",
    "\n",
    "**The main issue with Decision Trees is that they are very sensitive to small variations in the training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
